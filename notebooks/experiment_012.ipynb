{
 "metadata": {
  "name": "",
  "signature": "sha256:a9fbbcef0759fb580763d7b180ea26395ab3689dcbb06ee10d52d128d3389cdc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import matplotlib\n",
      "matplotlib.use('nbagg') # interactive plots in iPython. New in matplotlib v1.4\n",
      "# %matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "from nilmtk import DataSet, MeterGroup\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from time import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Couldn't import dot_parser, loading of dot files will not be possible.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/bottleneck/__init__.py:13: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .func import (nansum, nanmax, nanmin, nanmean, nanstd, nanvar, median,\n",
        "/usr/local/lib/python2.7/dist-packages/bottleneck/__init__.py:19: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
        "  from .move import (move_sum, move_nansum,\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.supervised import RPropMinusTrainer\n",
      "from pybrain.datasets import SequentialDataSet\n",
      "from pybrain.structure import RecurrentNetwork, FullConnection\n",
      "from pybrain.structure.modules import LSTMLayer, BiasUnit, LinearLayer, TanhLayer, SigmoidLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONFIG = dict(\n",
      "    EPOCHS_PER_CYCLE = 5,\n",
      "    CYCLES = 30,\n",
      "    HIDDEN_LAYERS = [50, 50],\n",
      "    PEEPHOLES = True,\n",
      "    TRAINERCLASS = RPropMinusTrainer,\n",
      "    # instead, you may also try\n",
      "    # TRAINERCLASS = BackpropTrainer(net, dataset=trndata, verbose=True, \n",
      "    #                                momentum=0.9, learningrate=0.00001)\n",
      "    INPUTS = ['fridge'], #, 'hour of day (int)', 'outside temperature', 'is business day (-1, 1)'\n",
      "    EXPERIMENT_NUMBER = 12\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load dataset\n",
      "dataset = DataSet('/data/mine/vadeec/merged/ukdale.h5')\n",
      "dataset.set_window(\"2014-01-01\", \"2014-05-01\")\n",
      "elec = dataset.buildings[1].elec"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Select top-5 meters identified in UK-DALE paper\n",
      "# APPLIANCES = ['kettle', 'dish washer', 'HTPC', 'washer dryer', 'fridge freezer']\n",
      "APPLIANCES = ['fridge freezer']\n",
      "selected_meters = [elec[appliance] for appliance in APPLIANCES]\n",
      "selected_meters.append(elec.mains())\n",
      "selected = MeterGroup(selected_meters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = selected.dataframe_of_meters()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use human-readable column names\n",
      "df.columns = selected.get_labels(df.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mains = df['Site meter'].diff().dropna()\n",
      "appliances = df.iloc[:,:-1].fillna(0).diff().dropna()\n",
      "del df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# standardise input\n",
      "mains = (mains - mains.mean()) / mains.std()\n",
      "\n",
      "# Constrain outputs to [-1,1] because we're using TanH\n",
      "appliances /= appliances.abs().max()\n",
      "# appliances -= 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#mains.plot()\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#appliances.plot()\n",
      "#plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build PyBrain dataset\n",
      "N_OUTPUTS = appliances.shape[1]\n",
      "N_INPUTS = 1\n",
      "N = len(mains)\n",
      "ds = SequentialDataSet(N_INPUTS, N_OUTPUTS)\n",
      "ds.newSequence()\n",
      "ds.setField('input', pd.DataFrame(mains).values)\n",
      "ds.setField('target', appliances.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds.getSequence(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/PyBrain-0.3.3-py2.7.egg/pybrain/datasets/sequential.py:45: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "  return self.getField(field)[seq[index]:]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[array([[ 0.04660185],\n",
        "        [-0.00324906],\n",
        "        [-0.07886962],\n",
        "        ..., \n",
        "        [ 0.00095862],\n",
        "        [ 0.00165413],\n",
        "        [ 0.00035003]]), array([[ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.],\n",
        "        ..., \n",
        "        [ 0.],\n",
        "        [ 0.],\n",
        "        [ 0.]])]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build network\n",
      "net = RecurrentNetwork()\n",
      "\n",
      "def lstm_layer_name(i):\n",
      "    return 'LSTM{:d}'.format(i)\n",
      "\n",
      "# Add modules\n",
      "net.addInputModule(LinearLayer(ds.indim, name='in'))\n",
      "net.addOutputModule(TanhLayer(dim=ds.outdim, name='out'))\n",
      "for i, n_cells in enumerate(CONFIG['HIDDEN_LAYERS']):\n",
      "    net.addModule(LSTMLayer(n_cells, name=lstm_layer_name(i+1), peepholes=CONFIG['PEEPHOLES']))   \n",
      "\n",
      "# Bias\n",
      "bias = BiasUnit()\n",
      "net.addModule(bias)\n",
      "c_output_bias = FullConnection(bias, net['out'], name='c_output_bias')\n",
      "c_output_bias._setParameters(np.zeros(1))\n",
      "net.addConnection(c_output_bias)\n",
      "    \n",
      "# Add other connections\n",
      "n_hidden_layers = len(CONFIG['HIDDEN_LAYERS'])\n",
      "prev_layer_name = 'in'\n",
      "for i in range(n_hidden_layers):\n",
      "    hidden_layer_i = i + 1\n",
      "    layer_name = lstm_layer_name(hidden_layer_i)\n",
      "    \n",
      "    recurrent_connection = FullConnection(net[layer_name], net[layer_name], name='c_' + layer_name + '_to_' + layer_name)\n",
      "    recurrent_connection._params = np.random.uniform(-0.05, 0.05, size=recurrent_connection.paramdim)\n",
      "    net.addRecurrentConnection(recurrent_connection)\n",
      "    \n",
      "    #bias_connection = FullConnection(bias, net[layer_name], name='c_' + layer_name + '_bias')\n",
      "    #bias_connection._params = np.zeros(bias_connection.paramdim)\n",
      "    #net.addConnection(bias_connection)\n",
      "    \n",
      "    forwards_connection = FullConnection(net[prev_layer_name], net[layer_name], name='c_' + prev_layer_name + '_to_' + layer_name)\n",
      "    forwards_connection._params = np.random.uniform(-0.2, 0.2, size=forwards_connection.paramdim)\n",
      "    net.addConnection(forwards_connection)\n",
      "    prev_layer_name = layer_name\n",
      "    \n",
      "layer_name = lstm_layer_name(n_hidden_layers)\n",
      "connect_to_out = FullConnection(net[layer_name], net['out'], name='c_' + layer_name + '_to_out')\n",
      "connect_to_out._params = np.random.uniform(-0.2, 0.2, size=connect_to_out.paramdim)\n",
      "net.addConnection(connect_to_out)\n",
      "\n",
      "net.sortModules()\n",
      "print(net)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RecurrentNetwork-6\n",
        "   Modules:\n",
        "    [<BiasUnit 'BiasUnit-5'>, <LinearLayer 'in'>, <LSTMLayer 'LSTM1'>, <LSTMLayer 'LSTM2'>, <TanhLayer 'out'>]\n",
        "   Connections:\n",
        "    [<FullConnection 'c_LSTM1_to_LSTM2': 'LSTM1' -> 'LSTM2'>, <FullConnection 'c_LSTM2_to_out': 'LSTM2' -> 'out'>, <FullConnection 'c_in_to_LSTM1': 'in' -> 'LSTM1'>, <FullConnection 'c_output_bias': 'BiasUnit-5' -> 'out'>]\n",
        "   Recurrent Connections:\n",
        "    [<FullConnection 'c_LSTM1_to_LSTM1': 'LSTM1' -> 'LSTM1'>, <FullConnection 'c_LSTM2_to_LSTM2': 'LSTM2' -> 'LSTM2'>]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define a training method\n",
      "#net.randomize()\n",
      "#net._setParameters(np.random.uniform(-0.2, 0.2, size=net.paramdim))\n",
      "trainer = CONFIG['TRAINERCLASS'](net, dataset=ds, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# carry out the training\n",
      "net.reset()\n",
      "# train_errors = []\n",
      "t0 = time()\n",
      "EPOCHS = CONFIG['EPOCHS_PER_CYCLE'] * CONFIG['CYCLES']\n",
      "# trainer.trainUntilConvergence(maxEpochs=EPOCHS, verbose=True)\n",
      "# start_time = time()\n",
      "print(\"Starting training with\", EPOCHS, \"epochs...\")\n",
      "for i in xrange(CONFIG['CYCLES']):\n",
      "    trainer.trainEpochs(CONFIG['EPOCHS_PER_CYCLE'])\n",
      "#    train_errors.append(trainer.testOnData())\n",
      "    # epoch = (i+1) * CONFIG['EPOCHS_PER_CYCLE']\n",
      "    # seconds_elapsed = time() - start_time\n",
      "    # seconds_per_epoch = seconds_elapsed / epoch\n",
      "    # seconds_remaining = (EPOCHS - epoch) * seconds_per_epoch\n",
      "    # td_elapsed = timedelta(seconds=seconds_elapsed)\n",
      "    # td_elapsed_str = str(td_elapsed).split('.')[0]\n",
      "    # eta = (datetime.now() + timedelta(seconds=seconds_remaining)).time()\n",
      "    # eta = eta.strftime(\"%H:%M:%S\")\n",
      "    # print(\"\\r epoch = {}/{}    error = {}  elapsed = {}   ETA = {}\"\n",
      "    #       .format(epoch, EPOCHS, train_errors[-1], td_elapsed_str, eta),\n",
      "    #       end=\"\")\n",
      "    # stdout.flush()\n",
      "print(\"Finished training.  total seconds =\", time() - t0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Disaggregate!\n",
      "START = \"2014-01-01\"\n",
      "END = \"2014-01-03\"\n",
      "print(\"Starting disaggregation...\")\n",
      "net.reset()\n",
      "estimates = pd.DataFrame(columns=appliances.columns, index=appliances[START:END].index)\n",
      "for date, mains_value in mains[START:END].iteritems():\n",
      "    estimates.loc[date] = net.activate(mains_value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimates.plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "appliances[START:END].plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mains[START:END].plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimates[START:END].cumsum().plot()\n",
      "#mains[START:END].cumsum().plot()\n",
      "appliances[START:END].cumsum().plot()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimates.cumsum().to_hdf('neuronilm_estimates_{:03d}.hdf'.format(CONFIG['EXPERIMENT_NUMBER']), 'df')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}