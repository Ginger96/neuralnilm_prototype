{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.tensor.nnet import conv\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code from http://deeplearning.net/tutorial/lenet.html\n",
    "rng = np.random.RandomState(23455)\n",
    "\n",
    "# instantiate 4D tensor for input\n",
    "input = T.tensor4(name='input')\n",
    "\n",
    "# initialize shared variable for weights.\n",
    "# The shape of the tensor is: \n",
    "#    0: number of feature maps at layer m   (i.e. the output)\n",
    "#    1: number of feature maps at layer m-1 (i.e. the input)\n",
    "#    2: filter height\n",
    "#    3: filter width\n",
    "# The input consists of 3 features maps (an RGB color image) of size 120x160.\n",
    "# We use two convolutional filters with 9x9 receptive fields.\n",
    "w_shape = (1, 3, 3, 3)\n",
    "w_bound = np.sqrt(1 * 3 * 3)\n",
    "W = theano.shared(\n",
    "    np.asarray(\n",
    "        rng.uniform(\n",
    "            low=0,   # -1.0 / w_bound,\n",
    "            high=1.0, #  / w_bound,\n",
    "            size=w_shape),\n",
    "        dtype=input.dtype),\n",
    "    name ='W')\n",
    "\n",
    "# build symbolic expression that computes the convolution of input with filters in w\n",
    "conv_out = conv.conv2d(input, filters=W, border_mode='valid')\n",
    "\n",
    "# ignoring biases for now\n",
    "output = conv_out\n",
    "\n",
    "# create theano function to compute filtered images\n",
    "f = theano.function([input], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open random image of dimensions 639x516\n",
    "img = Image.open(open('3wolfmoon.jpg'))\n",
    "# dimensions are (height, width, channel)\n",
    "img = numpy.asarray(img, dtype='float64') / 256.\n",
    "\n",
    "# make B&W\n",
    "# img = img.mean(axis=2, keepdims=True)\n",
    "\n",
    "# put image in 4D tensor of shape (1, 3, height, width)\n",
    "img_ = img.transpose(2, 0, 1).reshape(1, 3, 639, 516)\n",
    "filtered_img = f(img_)\n",
    "\n",
    "# plot original image and first and second components of output\n",
    "pylab.subplot(1, 3, 1); pylab.axis('off'); pylab.imshow(img[:,:,:])\n",
    "pylab.gray();\n",
    "# recall that the convOp output (filtered image) is actually a \"minibatch\",\n",
    "# of size 1 here, so we take index 0 in the first dimension:\n",
    "pylab.subplot(1, 3, 2); pylab.axis('off'); pylab.imshow(filtered_img[0, 0, :, :])\n",
    "#pylab.subplot(1, 3, 3); pylab.axis('off'); pylab.imshow(filtered_img[0, 1, :, :])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 637, 514)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 516, 3)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv_W = W.transpose([1, 0, 2, 3])\n",
    "deconv_W = deconv_W[:, :, ::-1, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate 4D tensor for input\n",
    "deconv_input = T.tensor4(name='deconv_input')\n",
    "deconv_out = conv.conv2d(deconv_input, filters=deconv_W, border_mode='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv_f = theano.function([deconv_input], deconv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deconv_img = deconv_f(filtered_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 639, 516)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deconv_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8375602d90>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pylab.subplot(1, 2, 1); pylab.imshow(img[:, :, :])\n",
    "pylab.subplot(1, 2, 2); pylab.imshow(deconv_img[0].transpose((1, 2, 0)) / deconv_img.max()) #)[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8377a2bb10>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum = deconv_img[0].min()\n",
    "deconv_img_rescaled = deconv_img[0].transpose(1, 2, 0) - minimum\n",
    "maximum = deconv_img_rescaled.max()\n",
    "deconv_img_rescaled = deconv_img_rescaled / maximum\n",
    "pylab.imshow(deconv_img_rescaled[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30811445678618993"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 637, 514)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.08203125],\n",
       "        [ 0.10677083],\n",
       "        [ 0.09505208],\n",
       "        ..., \n",
       "        [ 0.0703125 ],\n",
       "        [ 0.06640625],\n",
       "        [ 0.08463542]],\n",
       "\n",
       "       [[ 0.0859375 ],\n",
       "        [ 0.10026042],\n",
       "        [ 0.08854167],\n",
       "        ..., \n",
       "        [ 0.04947917],\n",
       "        [ 0.0625    ],\n",
       "        [ 0.07552083]],\n",
       "\n",
       "       [[ 0.09635417],\n",
       "        [ 0.10026042],\n",
       "        [ 0.0859375 ],\n",
       "        ..., \n",
       "        [ 0.05729167],\n",
       "        [ 0.08854167],\n",
       "        [ 0.07161458]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.05729167],\n",
       "        [ 0.078125  ],\n",
       "        [ 0.05729167],\n",
       "        ..., \n",
       "        [ 0.07161458],\n",
       "        [ 0.08333333],\n",
       "        [ 0.09114583]],\n",
       "\n",
       "       [[ 0.0390625 ],\n",
       "        [ 0.05338542],\n",
       "        [ 0.046875  ],\n",
       "        ..., \n",
       "        [ 0.06380208],\n",
       "        [ 0.07161458],\n",
       "        [ 0.07552083]],\n",
       "\n",
       "       [[ 0.04296875],\n",
       "        [ 0.04557292],\n",
       "        [ 0.03776042],\n",
       "        ..., \n",
       "        [ 0.07161458],\n",
       "        [ 0.06770833],\n",
       "        [ 0.05208333]]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0025961977401517946"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(deconv_img / 175).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
