{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/workspace/python/Lasagne/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:11: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/__init__.py:3: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/_graph_validation.py:5: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._graph_tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/__init__.py:4: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._traversal import connected_components\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:20: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ..utils.sparsefuncs import inplace_csr_row_normalize_l1\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/cluster/supervised.py:19: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:14: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py:52: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .pairwise_fast import _chi2_kernel_fast\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "from os.path import join, expanduser\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml  # for pretty-printing dict\n",
    "from neuralnilm.metrics import run_metrics, across_all_appliances\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn evokes warnings from numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_HOUSES = {\n",
    "    'microwave': (1, 2),\n",
    "    'fridge': (1, 2, 4),\n",
    "    'dish washer': (1, 2),\n",
    "    'kettle': (1, 2, 4),\n",
    "    'washing machine': (1, 5)\n",
    "}\n",
    "\n",
    "TEST_HOUSES = {\n",
    "    'microwave': (5,),\n",
    "    'fridge': (5,),\n",
    "    'dish washer': (5,),\n",
    "    'kettle': (5,),\n",
    "    'washing machine': (2,)\n",
    "}\n",
    "\n",
    "APPLIANCES = TRAIN_HOUSES.keys()\n",
    "\n",
    "ON_POWER_THRESHOLDS = {\n",
    "    'microwave': 200,\n",
    "    'fridge': 50,\n",
    "    'dish washer': 10,\n",
    "    'kettle': 2000,\n",
    "    'washing machine': 20\n",
    "}\n",
    "\n",
    "HOUSES = [1, 2, 3, 4, 5]\n",
    "\n",
    "METRICS = [\n",
    "    'f1_score',\n",
    "    'precision_score',\n",
    "    'recall_score',\n",
    "    'accuracy_score',\n",
    "    'relative_error_in_total_energy',\n",
    "    'total_energy_correctly_assigned',\n",
    "    'mean_absolute_error'\n",
    "]\n",
    "\n",
    "# ALGORITHMS = ['co', 'fhmm', 'ae', 'rectangles', 'rnn']\n",
    "\n",
    "ALGORITHMS = ['co', 'fhmm', 'ae', 'rectangles']\n",
    "\n",
    "full_algorithm_names = [\n",
    "    'Combinatorial Optimisation ', 'Factorial HMM', 'Autoencoder', 'Rectangles']\n",
    "\n",
    "\n",
    "ESTIMATES_PATH = expanduser(\n",
    "    \"~/PhD/experiments/neural_nilm/data_for_BuildSys2015/disag_estimates\")\n",
    "GROUND_TRUTH_PATH = expanduser(\n",
    "    \"~/PhD/experiments/neural_nilm/data_for_BuildSys2015/ground_truth_and_mains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO mean and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(architecture, building_i, appliance):\n",
    "    # load estimates\n",
    "    estimates_fname = \"{}_building_{}_estimates_{}.csv\".format(\n",
    "        architecture, building_i, appliance)\n",
    "    estimates_fname = join(ESTIMATES_PATH, estimates_fname)\n",
    "    y_pred = np.loadtxt(estimates_fname, delimiter=',')\n",
    "\n",
    "    # load ground truth\n",
    "    y_true_fname = \"building_{}_{}.csv\".format(building_i, appliance.replace(' ', '_'))\n",
    "    y_true_fname = join(GROUND_TRUTH_PATH, y_true_fname)\n",
    "    y_true = np.loadtxt(y_true_fname, delimiter=',')\n",
    "\n",
    "    # load mains\n",
    "    mains_fname = \"building_{}_mains.csv\".format(building_i)\n",
    "    mains_fname = join(GROUND_TRUTH_PATH, mains_fname)\n",
    "    mains = np.loadtxt(mains_fname, delimiter=',')\n",
    "\n",
    "    return y_true, y_pred, mains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_all(y_true, y_pred, mains, title=None):\n",
    "    fig, axes = plt.subplots(nrows=3, sharex=True)\n",
    "    axes[0].plot(y_pred)\n",
    "    axes[0].set_title('y_pred')\n",
    "    axes[1].plot(y_true)\n",
    "    axes[1].set_title('y_true')\n",
    "    axes[2].plot(mains)\n",
    "    axes[2].set_title('mains')\n",
    "    if title:\n",
    "        fig.set_title(title)\n",
    "    plt.show()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x7fd949085350>,\n",
       " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fd948e6d990>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd94856ae90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd9484ef9d0>], dtype=object))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_metrics(houses):\n",
    "    scores = pd.Panel(\n",
    "        np.NaN,\n",
    "        items=APPLIANCES,\n",
    "        major_axis=METRICS,\n",
    "        minor_axis=ALGORITHMS\n",
    "    )\n",
    "    \n",
    "    for appliance in APPLIANCES:\n",
    "        houses_for_appliance = houses[appliance]\n",
    "        on_power_threshold = ON_POWER_THRESHOLDS[appliance]\n",
    "        for algo in ALGORITHMS:\n",
    "            house_scores = pd.DataFrame(\n",
    "                np.NaN, columns=METRICS, index=houses_for_appliance)\n",
    "            for house_i in houses_for_appliance:\n",
    "                y_true, y_pred, mains = load(algo, house_i, appliance)\n",
    "                house_scores_dict = run_metrics(\n",
    "                    y_true, y_pred, mains, on_power_threshold)\n",
    "                house_scores_dict.pop('sum_abs_diff')\n",
    "                house_scores.loc[house_i] = house_scores_dict\n",
    "            scores[appliance, :, algo].update(house_scores.dropna().mean())\n",
    "                \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_houses_scores = calc_metrics(TEST_HOUSES)\n",
    "train_houses_scores = calc_metrics(TRAIN_HOUSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>fhmm</th>\n",
       "      <th>ae</th>\n",
       "      <th>rectangles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.345734</td>\n",
       "      <td>0.549839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.684371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.300388</td>\n",
       "      <td>0.403669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.605539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.407204</td>\n",
       "      <td>0.861959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.450810</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.643657</td>\n",
       "      <td>0.741389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_error_in_total_energy</th>\n",
       "      <td>0.371471</td>\n",
       "      <td>0.566832</td>\n",
       "      <td>-0.528532</td>\n",
       "      <td>-0.016614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_correctly_assigned</th>\n",
       "      <td>0.940019</td>\n",
       "      <td>0.944801</td>\n",
       "      <td>0.963745</td>\n",
       "      <td>0.975478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>73.275903</td>\n",
       "      <td>67.433414</td>\n",
       "      <td>44.290833</td>\n",
       "      <td>29.957072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        co       fhmm         ae  rectangles\n",
       "f1_score                          0.345734   0.549839   0.000000    0.684371\n",
       "precision_score                   0.300388   0.403669   0.000000    0.605539\n",
       "recall_score                      0.407204   0.861959   0.000000    0.786800\n",
       "accuracy_score                    0.450810   0.497060   0.643657    0.741389\n",
       "relative_error_in_total_energy    0.371471   0.566832  -0.528532   -0.016614\n",
       "total_energy_correctly_assigned   0.940019   0.944801   0.963745    0.975478\n",
       "mean_absolute_error              73.275903  67.433414  44.290833   29.957072"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPLIANCE = 'fridge'\n",
    "test_houses_scores[APPLIANCE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>fhmm</th>\n",
       "      <th>ae</th>\n",
       "      <th>rectangles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.520795</td>\n",
       "      <td>0.471406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.544079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.499031</td>\n",
       "      <td>0.385641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.544940</td>\n",
       "      <td>0.628293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.611349</td>\n",
       "      <td>0.463754</td>\n",
       "      <td>0.614414</td>\n",
       "      <td>0.667419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_error_in_total_energy</th>\n",
       "      <td>0.262454</td>\n",
       "      <td>0.495344</td>\n",
       "      <td>-0.514447</td>\n",
       "      <td>-0.267002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_correctly_assigned</th>\n",
       "      <td>0.937376</td>\n",
       "      <td>0.911494</td>\n",
       "      <td>0.946837</td>\n",
       "      <td>0.958188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>49.750708</td>\n",
       "      <td>69.067558</td>\n",
       "      <td>40.582481</td>\n",
       "      <td>32.214409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        co       fhmm         ae  rectangles\n",
       "f1_score                          0.520795   0.471406   0.000000    0.544079\n",
       "precision_score                   0.499031   0.385641   0.000000    0.578835\n",
       "recall_score                      0.544940   0.628293   0.000000    0.518748\n",
       "accuracy_score                    0.611349   0.463754   0.614414    0.667419\n",
       "relative_error_in_total_energy    0.262454   0.495344  -0.514447   -0.267002\n",
       "total_energy_correctly_assigned   0.937376   0.911494   0.946837    0.958188\n",
       "mean_absolute_error              49.750708  69.067558  40.582481   32.214409"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_houses_scores[APPLIANCE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x7fd947a7de10>,\n",
       " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fd947a75dd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd947a4ef50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd9479cde10>], dtype=object))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred, mains = load('rectangles', 2, APPLIANCE)\n",
    "plot_all(y_true, y_pred, mains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "COLOR = ['#5F7343', '#99A63C', '#FEC06A', '#F25430', '#E61924']\n",
    "nrows = len(METRICS)\n",
    "ncols = len(APPLIANCES)\n",
    "n_algorithms = len(ALGORITHMS)\n",
    "x = range(n_algorithms)\n",
    "FONTSIZE = 10\n",
    "\n",
    "def plot_scores(scores):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharey='row', figsize=(8.1, 8.7))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for row_i, metric in enumerate(METRICS):\n",
    "        for col_i, appliance in enumerate(APPLIANCES):\n",
    "            ax = axes[row_i, col_i]\n",
    "            scores_for_algorithms = scores[appliance, metric]\n",
    "            rects = ax.bar(\n",
    "                x, scores_for_algorithms, color=COLOR, edgecolor=COLOR, zorder=3)\n",
    "\n",
    "            # Numbers on the plot\n",
    "            if row_i == 6:  # mean absolute error (watts)\n",
    "                text_y = 150\n",
    "                text_format = '{:3.0f}'\n",
    "            else:\n",
    "                text_y = 0.5\n",
    "                text_format = '{:.2f}'\n",
    "\n",
    "            # Draw text\n",
    "            for i, rect in enumerate(rects):\n",
    "                ax.text(\n",
    "                    rect.get_x() + rect.get_width() / 2.5,\n",
    "                    text_y,\n",
    "                    text_format.format(scores_for_algorithms[i]),\n",
    "                    va='center', rotation=90, fontsize=FONTSIZE)\n",
    "\n",
    "            # Formatting\n",
    "            ax.set_xticks([])\n",
    "            ax.tick_params(direction='out')\n",
    "            ax.yaxis.grid(\n",
    "                b=True, which='major', color='white', linestyle='-', zorder=0)\n",
    "            ax.patch.set_facecolor((0.85, 0.85, 0.85))\n",
    "\n",
    "            if row_i == 4:  # relative error in total energy\n",
    "                ax.set_ylim((-1, 1))\n",
    "\n",
    "            for spine in ['top', 'right', 'left', 'bottom']:\n",
    "                ax.spines[spine].set_visible(False)\n",
    "\n",
    "            if row_i == 0:\n",
    "                if appliance == 'across all appliances':\n",
    "                    label = 'Across all\\nappliances'\n",
    "                else:\n",
    "                    label = appliance.replace(' ', '\\n')\n",
    "                    label = label[0].capitalize() + label[1:]\n",
    "                ax.set_title(label, fontsize=FONTSIZE)\n",
    "            if col_i == 0:\n",
    "                label = metric.replace('_', '\\n')\n",
    "                if label == 'mean\\nabsolute\\nerror':\n",
    "                    label = label + '\\n(watts)'\n",
    "                elif label == 'total\\nenergy\\ncorrectly\\nassigned':\n",
    "                    label = 'prop. of\\n' + label\n",
    "                elif label == 'relative\\nerror\\nin\\ntotal\\nenergy':\n",
    "                    label = 'relative\\nerror in\\ntotal\\nenergy'\n",
    "                label = label[0].capitalize() + label[1:]\n",
    "                ylabel = ax.set_ylabel(label, fontsize=FONTSIZE)\n",
    "                ylabel.set_rotation('horizontal')\n",
    "                ylabel.set_verticalalignment('center')\n",
    "                ylabel.set_horizontalalignment('center')\n",
    "                ax.yaxis.labelpad = 25\n",
    "                ax.tick_params(axis='y', left='on', right='off')\n",
    "            else:\n",
    "                ax.tick_params(axis='y', left='off', right='off')\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    plt.legend(rects, full_algorithm_names, ncol=n_algorithms, loc=(-5, -0.8),\n",
    "               frameon=False)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plot_scores(test_houses_scores)\n",
    "#fig.suptitle('Unseen houses', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plot_scores(train_houses_scores)\n",
    "#fig.suptitle('Train houses', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
