{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/workspace/python/Lasagne/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/__init__.py:11: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .murmurhash import murmurhash3_32\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/__init__.py:3: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._min_spanning_tree import minimum_spanning_tree\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/_graph_validation.py:5: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._graph_tools import csgraph_to_dense, csgraph_from_dense,\\\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/sparsetools/__init__.py:4: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._traversal import connected_components\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:20: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ..utils.sparsefuncs import inplace_csr_row_normalize_l1\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/cluster/supervised.py:19: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .expected_mutual_info_fast import expected_mutual_information\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/extmath.py:14: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from ._logistic_sigmoid import _log_logistic_sigmoid\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py:52: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility\n",
      "  from .pairwise_fast import _chi2_kernel_fast\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "from os.path import join, expanduser\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml  # for pretty-printing dict\n",
    "from neuralnilm.metrics import run_metrics, across_all_appliances\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn evokes warnings from numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_HOUSES = {\n",
    "    'microwave': (1, 2),\n",
    "    'fridge': (1, 2, 4),\n",
    "    'dish washer': (1, 2),\n",
    "    'kettle': (1, 2, 4),\n",
    "    'washing machine': (1, 5)\n",
    "}\n",
    "\n",
    "TEST_HOUSES = {\n",
    "    'microwave': (5,),\n",
    "    'fridge': (5,),\n",
    "    'dish washer': (5,),\n",
    "    'kettle': (5,),\n",
    "    'washing machine': (2,)\n",
    "}\n",
    "\n",
    "APPLIANCES = TRAIN_HOUSES.keys()\n",
    "\n",
    "ON_POWER_THRESHOLDS = {\n",
    "    'microwave': 200,\n",
    "    'fridge': 50,\n",
    "    'dish washer': 10,\n",
    "    'kettle': 2000,\n",
    "    'washing machine': 20\n",
    "}\n",
    "\n",
    "HOUSES = [1, 2, 3, 4, 5]\n",
    "\n",
    "METRICS = [\n",
    "    'f1_score',\n",
    "    'precision_score',\n",
    "    'recall_score',\n",
    "    'accuracy_score',\n",
    "    'relative_error_in_total_energy',\n",
    "    'total_energy_correctly_assigned',\n",
    "    'mean_absolute_error'\n",
    "]\n",
    "\n",
    "# ALGORITHMS = ['co', 'fhmm', 'ae', 'rectangles', 'rnn']\n",
    "\n",
    "ALGORITHMS = ['co', 'fhmm', 'ae', 'rectangles']\n",
    "\n",
    "\n",
    "ESTIMATES_PATH = expanduser(\n",
    "    \"~/PhD/experiments/neural_nilm/data_for_BuildSys2015/disag_estimates\")\n",
    "GROUND_TRUTH_PATH = expanduser(\n",
    "    \"~/PhD/experiments/neural_nilm/data_for_BuildSys2015/ground_truth_and_mains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO mean and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(architecture, building_i, appliance):\n",
    "    # load estimates\n",
    "    estimates_fname = \"{}_building_{}_estimates_{}.csv\".format(\n",
    "        architecture, building_i, appliance)\n",
    "    estimates_fname = join(ESTIMATES_PATH, estimates_fname)\n",
    "    y_pred = np.loadtxt(estimates_fname, delimiter=',')\n",
    "\n",
    "    # load ground truth\n",
    "    y_true_fname = \"building_{}_{}.csv\".format(building_i, appliance.replace(' ', '_'))\n",
    "    y_true_fname = join(GROUND_TRUTH_PATH, y_true_fname)\n",
    "    y_true = np.loadtxt(y_true_fname, delimiter=',')\n",
    "\n",
    "    # load mains\n",
    "    mains_fname = \"building_{}_mains.csv\".format(building_i)\n",
    "    mains_fname = join(GROUND_TRUTH_PATH, mains_fname)\n",
    "    mains = np.loadtxt(mains_fname, delimiter=',')\n",
    "\n",
    "    return y_true, y_pred, mains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_all(y_true, y_pred, mains, title=None):\n",
    "    fig, axes = plt.subplots(nrows=3, sharex=True)\n",
    "    axes[0].plot(y_pred)\n",
    "    axes[0].set_title('y_pred')\n",
    "    axes[1].plot(y_true)\n",
    "    axes[1].set_title('y_true')\n",
    "    axes[2].plot(mains)\n",
    "    axes[2].set_title('mains')\n",
    "    if title:\n",
    "        fig.set_title(title)\n",
    "    plt.show()\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x7fd94b4fbb90>,\n",
       " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fd94b4defd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd94b4832d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd94b3eecd0>], dtype=object))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred, mains = load('rectangles', 2, 'washing machine')\n",
    "plot_all(y_true, y_pred, mains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_metrics(houses):\n",
    "    scores = pd.Panel(\n",
    "        np.NaN,\n",
    "        items=APPLIANCES,\n",
    "        major_axis=METRICS,\n",
    "        minor_axis=ALGORITHMS\n",
    "    )\n",
    "    \n",
    "    for appliance in APPLIANCES:\n",
    "        houses_for_appliance = houses[appliance]\n",
    "        on_power_threshold = ON_POWER_THRESHOLDS[appliance]\n",
    "        for algo in ALGORITHMS:\n",
    "            house_scores = pd.DataFrame(\n",
    "                np.NaN, columns=METRICS, index=houses_for_appliance)\n",
    "            for house_i in houses_for_appliance:\n",
    "                y_true, y_pred, mains = load(algo, house_i, appliance)\n",
    "                house_scores_dict = run_metrics(\n",
    "                    y_true, y_pred, mains, on_power_threshold)\n",
    "                house_scores_dict.pop('sum_abs_diff')\n",
    "                house_scores.loc[house_i] = house_scores_dict\n",
    "            scores[appliance, :, algo].update(house_scores.dropna().mean())\n",
    "                \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [ True]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [ True]. \n",
      "  average=average)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1734: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [ True]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [ True]. \n",
      "  average=average)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1809: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [ True]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [ True]. \n",
      "  average=average)\n"
     ]
    }
   ],
   "source": [
    "test_houses_scores = calc_metrics(TEST_HOUSES)\n",
    "train_houses_scores = calc_metrics(TRAIN_HOUSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>fhmm</th>\n",
       "      <th>ae</th>\n",
       "      <th>rectangles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.101690</td>\n",
       "      <td>0.077404</td>\n",
       "      <td>0.080348</td>\n",
       "      <td>0.256343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.056811</td>\n",
       "      <td>0.041181</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.165784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.484127</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.999278</td>\n",
       "      <td>0.564935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.882384</td>\n",
       "      <td>0.789273</td>\n",
       "      <td>0.685448</td>\n",
       "      <td>0.954928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_error_in_total_energy</th>\n",
       "      <td>0.734942</td>\n",
       "      <td>0.859433</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.392474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_correctly_assigned</th>\n",
       "      <td>0.930384</td>\n",
       "      <td>0.881886</td>\n",
       "      <td>0.915642</td>\n",
       "      <td>0.960130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>39.467577</td>\n",
       "      <td>66.962825</td>\n",
       "      <td>47.825327</td>\n",
       "      <td>22.603756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        co       fhmm         ae  rectangles\n",
       "f1_score                          0.101690   0.077404   0.080348    0.256343\n",
       "precision_score                   0.056811   0.041181   0.041857    0.165784\n",
       "recall_score                      0.484127   0.642857   0.999278    0.564935\n",
       "accuracy_score                    0.882384   0.789273   0.685448    0.954928\n",
       "relative_error_in_total_energy    0.734942   0.859433   0.793860    0.392474\n",
       "total_energy_correctly_assigned   0.930384   0.881886   0.915642    0.960130\n",
       "mean_absolute_error              39.467577  66.962825  47.825327   22.603756"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_houses_scores['washing machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>fhmm</th>\n",
       "      <th>ae</th>\n",
       "      <th>rectangles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.128903</td>\n",
       "      <td>0.111168</td>\n",
       "      <td>0.170956</td>\n",
       "      <td>0.493600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>0.075282</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.406556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>0.564659</td>\n",
       "      <td>0.869108</td>\n",
       "      <td>0.987060</td>\n",
       "      <td>0.654670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.687574</td>\n",
       "      <td>0.385451</td>\n",
       "      <td>0.607981</td>\n",
       "      <td>0.952655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_error_in_total_energy</th>\n",
       "      <td>0.648831</td>\n",
       "      <td>0.759248</td>\n",
       "      <td>0.593518</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_correctly_assigned</th>\n",
       "      <td>0.920369</td>\n",
       "      <td>0.877248</td>\n",
       "      <td>0.937901</td>\n",
       "      <td>0.966845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>87.919616</td>\n",
       "      <td>137.529573</td>\n",
       "      <td>68.813939</td>\n",
       "      <td>36.061682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        co        fhmm         ae  rectangles\n",
       "f1_score                          0.128903    0.111168   0.170956    0.493600\n",
       "precision_score                   0.075282    0.061310   0.095699    0.406556\n",
       "recall_score                      0.564659    0.869108   0.987060    0.654670\n",
       "accuracy_score                    0.687574    0.385451   0.607981    0.952655\n",
       "relative_error_in_total_energy    0.648831    0.759248   0.593518    0.019048\n",
       "total_energy_correctly_assigned   0.920369    0.877248   0.937901    0.966845\n",
       "mean_absolute_error              87.919616  137.529573  68.813939   36.061682"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_houses_scores['washing machine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
