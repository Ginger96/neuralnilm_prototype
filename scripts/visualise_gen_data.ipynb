{
 "metadata": {
  "name": "",
  "signature": "sha256:addfa18f7fa60e7b11f9a2352ba0fd57f709de4e340a1ffd441f965ee0cacc4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function, division\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "# from gen_data_029 import gen_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sequence length\n",
      "LENGTH = 400\n",
      "# Number of units in the hidden (recurrent) layer\n",
      "N_HIDDEN = 5\n",
      "# Number of training sequences in each batch\n",
      "N_BATCH = 30\n",
      "# SGD learning rate\n",
      "LEARNING_RATE = 1e-1\n",
      "# Number of iterations to train the net\n",
      "N_ITERATIONS = 200\n",
      "\n",
      "\n",
      "def quantized(inp):\n",
      "    n = 10\n",
      "    n_batch, length, _ = inp.shape\n",
      "    out = np.zeros(shape=(n_batch, length, n))\n",
      "    for i_batch in range(n_batch):\n",
      "        for i_element in range(length):\n",
      "            out[i_batch,i_element,:], _ = np.histogram(inp[i_batch, i_element, 0], [-1,-.8,-.6,-.4,-.2,0.0,.2,.4,.6,.8,1])\n",
      "    return (out * 2) - 1\n",
      "\n",
      "def gen_single_appliance(length, power, on_duration, min_off_duration=20, \n",
      "                         fdiff=True):\n",
      "    if fdiff:\n",
      "        length += 1\n",
      "    appliance_power = np.zeros(shape=(length))\n",
      "    i = 0\n",
      "    while i < length:\n",
      "        if np.random.binomial(n=1, p=0.2):\n",
      "            end = min(i + on_duration, length)\n",
      "            appliance_power[i:end] = power\n",
      "            i += on_duration + min_off_duration\n",
      "        else:\n",
      "            i += 1\n",
      "    return np.diff(appliance_power) if fdiff else appliance_power\n",
      "\n",
      "def gen_batches_of_single_appliance(length, n_batch, *args, **kwargs):\n",
      "    batches = np.zeros(shape=(n_batch, length, 1))\n",
      "    for i in range(n_batch):\n",
      "        batches[i, :, :] = gen_single_appliance(length, *args, **kwargs).reshape(length, 1)\n",
      "    return batches\n",
      "\n",
      "def gen_data(length=LENGTH, n_batch=N_BATCH, n_appliances=2, \n",
      "             appliance_powers=[10,20], \n",
      "             appliance_on_durations=[10,2]):\n",
      "    '''Generate a simple energy disaggregation data.\n",
      "\n",
      "    :parameters:\n",
      "        - length : int\n",
      "            Length of sequences to generate\n",
      "        - n_batch : int\n",
      "            Number of training sequences per batch\n",
      "\n",
      "    :returns:\n",
      "        - X : np.ndarray, shape=(n_batch, length, 1)\n",
      "            Input sequence\n",
      "        - y : np.ndarray, shape=(n_batch, length, 1)\n",
      "            Target sequence, appliance 1\n",
      "    '''\n",
      "    y = gen_batches_of_single_appliance(length, n_batch, \n",
      "                                        power=appliance_powers[0], \n",
      "                                        on_duration=appliance_on_durations[0])\n",
      "    X = y.copy()\n",
      "    for power, on_duration in zip(appliance_powers, appliance_on_durations)[1:]:\n",
      "        X += gen_batches_of_single_appliance(length, n_batch, power=power, on_duration=on_duration)\n",
      "\n",
      "    max_power = np.sum(appliance_powers)\n",
      "    \n",
      "    return quantized(X / max_power), y / max_power\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = gen_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(y[0])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "array([[-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1.,  1., -1.],\n",
        "       ..., \n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.],\n",
        "       [-1., -1., -1., ..., -1., -1., -1.]])"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(np.cumsum(y, axis=1)[0,:,:])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.mean(((np.cumsum(y, axis=1) - np.cumsum(y+1, axis=1)) / 1000)**2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.053533500000000005"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.cumsum(y+0.6, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "array([[[   0.6       ],\n",
        "        [   1.2       ],\n",
        "        [   1.8       ],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.73333333],\n",
        "        [ 240.33333333]],\n",
        "\n",
        "       [[   0.6       ],\n",
        "        [   1.53333333],\n",
        "        [   2.13333333],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.4       ],\n",
        "        [ 240.        ]],\n",
        "\n",
        "       [[   0.6       ],\n",
        "        [   1.2       ],\n",
        "        [   2.13333333],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.4       ],\n",
        "        [ 240.        ]],\n",
        "\n",
        "       ..., \n",
        "       [[   0.6       ],\n",
        "        [   1.2       ],\n",
        "        [   1.8       ],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.4       ],\n",
        "        [ 240.        ]],\n",
        "\n",
        "       [[   0.93333333],\n",
        "        [   1.53333333],\n",
        "        [   2.13333333],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.4       ],\n",
        "        [ 240.        ]],\n",
        "\n",
        "       [[   0.6       ],\n",
        "        [   1.2       ],\n",
        "        [   1.8       ],\n",
        "        ..., \n",
        "        [ 238.8       ],\n",
        "        [ 239.4       ],\n",
        "        [ 240.        ]]])"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}