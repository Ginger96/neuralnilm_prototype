357:
went back to doing regression using FF net.


------- RESULTS ---------


WORKS (kind of):

3 appliances
124
126
138
139 quantization!
142 
145
148
157a not great
158 not bad

180 mse

5 appliances
129: gets the fridge (once)!
cross entropy, scale appliances

131c: probably the best for all 5 appliances
cross entropy, scale appliances, first 2 layers are dense layers

132a: about as good as 131c
cross entropy, scale appliances, first 2 layers are dense layers

132c: not as good as 131c

134a: not great but kind of works

137a: not great but kind of works
similar to 131c, but lots of pretraining

156: not great


Integration works (with no noise!): 413 

Integration works (kind of) with 3 appliances: 418.  Needs more
training?


424: attempt to get a net to remember a sequence of 256 numbers didn't
work very well at all!

########## FF AUTO ENCODER FOR SINGLE APPLIANCE

425: FF auto encoder with single appliance (Fridge)
RESULTS: works pretty well. Not perfectly.

426: add hair straighteners and TV.  Didn't learn well.  Maybe because
learning rate was too high to start???

427: Kind of worked.  Didn't do a great job of denoising.

428: Conv1D layer at bottom.  Worked well once I stopped saturating
the first dense layer!

429: 2 conv layers.  Down to a 32-dimensional vector in middle.  Works
pretty well!

430: 2 conv layers.  Down to a 16-dimensional vector in middle.
Appears to work as well as 32D vector.

431: try 4D vector in middle (!)  Works just as well!!!!

432: 5 appliances. 20% chance of skipping target appliance.  Still
comes down to 4D vector in middle ;)  Incredible results! Almost
certainly the best results I've had with all 5 appliances. Main issue
is a few false positives.

433: Exact same network as 432. But washer is target (not fridge).
It works really really well!!!

434: Same as 433 but with batch norm after every layer.

435: Same as *432* but with different houses for validation
and training.  Works pretty well.  But might be overfitting.

436: same as 435 but move house 4 from train to validation, and double
SEQ_LENGTH to 1024, and bring learning rate down faster.

437: Add dropout to 436.  Can't get it to run.  SHOULD TRY AGAIN.

438: 434 (dropout) with Source from 437 (i.e. houses 1,2,3 for train,
houses 4,5 for validation).  Try again!

439: 434 but longer seq and longer train.

440: 439 but 2048 seq and 32D middle layer
RESULTS: Hmm, didn't work well at all. Let's go back to
SEQ_LENGTH=1024

441: 440 but SEQ_LENGTH=1024

442: 441 but grid search over size of middle layer (1 to 64) and batch
norm / no batch norm
RESULTS: the larger the net, the better the performance HOWEVER, this
is unsurprising.  We need to compare validation costs on unseen houses
and data.

443: like 442m (32D middle, no batch norm, avg for 25 best = 0.131),
 experiment with conv or no conv
  a) remove 1 conv layer (0.140)
  b) remove both conv layers (0.156)
  c) 3 conv layers (0.131)
  d) 2 conv layers, double number of filters to 32 (0.134)
  e) 2 conv layers, 16 filters each, halve filter length to 2 (0.155)
  f) filter length = 3 (0.140)
  g) filter length = 8 (0.135)

444: just testing new dimshuffle layer

445: first test of DeConv1DLayer.  Just washing machine and hair straighteners.
  Works pretty well!
  Looks like we do want to reverse the last dimension of the weights,
  as per
  https://github.com/ChienliMa/DeConvNet/blob/master/DeConvNet/CPRStage.py#L118

446: DeConv1DLayer in a full AE

a: just 2 linear dense layers, tied weights, no conv
   avg valid cost =  0.0498397239 

b: just 2 linear conv layers, tied weights
   avg valid cost =  0.4122743905
   
c: 2 conv layers, tied weights, 1 rectify dense layer in between
   avg valid cost =  0.0315488130

d: b but with 4 filters
   avg valid cost =  0.4122795463
   
e: c but learning rate 1e-1 for all 50,000 iterations
   avg valid cost =  0.0151113402
   pretty stunning output. 20 is good example (with noise)
   Perhaps not perfect suppression of hair straighteners (see 27).  

f: 2 conv layers, tied weights, 1 dense linear layer in between
   avg valid cost =  0.0307678953
   
g: full AE with tied weights and 1 conv layer
   avg valid cost =  0.0442434102
   output looks pretty perfect ;) (apart from being a little 'blurry')

h: 4 linear convs, no dense layers, tied weights
   avg valid cost =  0.4093216062

i: 4 linear convs, no dense layers, untied weights
   avg valid cost =  0.4090858698

j: like g (full AE) but untied weights for conv layers
   avg valid cost =  0.0453109629

k: like g (full AE) but untied weights all through
   avg valid cost =  0.0438082032
   does better job than 'e' at suppressing hair straighteners (see 27)

l: like g (full AE) but untied weights for conv layers
   avg valid cost =  0.0452575982

m: like k but LR=1e-1 for all 50,000 epochs
   avg valid cost =  0.0318283364

n: like k but LR=1e-1 for all 50,000 epochs and only 
   3 middle dense layers (4084 x ReLU, 1021 x ReLU, 4084 x linear)
   Looks excellent. Pretty much as good reconstruction as 'e' but
   better suppression.
   avg valid cost =  0.0125398841

o: n but last dense layer is ReLU
   avg valid cost =  0.0108001959  <-- BEST YET!

p: n but with 4 conv layer. (set LR=0.01 manually)
   avg valid cost =  0.0290298369

q: n but only 128-d middle layer & rectify final dense layer
   I changed LR to 0.01 around 42000 iterations.
   avg valid cost =  0.0238524191

r: n but target is fridge & rectify final dense layer
   change LR=0.01 around 28000 iterations

t: n but target is TV & rectify final dense layer
   not bad but confuses TV and Fridge (e.g. see 10)
   IDEA: maybe try two conv layers at front to try to detect
   oscillations?  Or more dense layers?
   avg valid cost =  0.2374919057

v: t but 2 input conv layers (linear)
   avg valid cost =  0.2364626676

w: o but with ReLU conv layers
   avg valid cost =  0.2731662989

x: o but with ReLU for input conv, linear for output conv
   avg valid cost =  0.0118574286

y: o but with linear for input conv, ReLU for output conv
   avg valid cost =  0.2745352983

447: first attempt to disaggregate real mains power (using network
   learnt in 446o).  doesn't work too well.  Lots of false positives.
   Hence next thing to do will be to train on real data.

448: train on real data!

449: Reduce seq length to 512 and use RandomSegmentsInMemory

450: Independently standardise each input

451: ignore incomplete activations

452:
a: don't centre inputs individually

b: reduce seq length to 256

c: reduced central layer to 4

d: reduced central layer to 8

e: reduced central layer to 32

f: reduce number of layers

g: no conv

TODO:
* ensure 75% of training examples include target.
* use same scaling factor for target and input
